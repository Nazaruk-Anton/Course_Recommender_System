{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nazaruk-Anton/Course_Recommender_System/blob/main/8_Collaborative_filtering_non_negative_matrix_factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWRnSCii5hYl"
      },
      "source": [
        "# **Collaborative Filtering based Recommender System using Non-negative Matrix Factorization**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYX7poE15hYo"
      },
      "source": [
        "#### Non-negative matrix factorization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4hjfS5L5hYp"
      },
      "source": [
        "Non-negative matrix factorization (NMF) decomposes a big sparse matrix into two smaller and dense matrices.\n",
        "\n",
        "Non-negative matrix factorization can be one solution to big matrix issues. The main idea is to decompose the big and sparse user-interaction into two smaller dense matrices, one represents the transformed user features and another represents the transformed item features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq4zRW-45hYq"
      },
      "source": [
        "An example is shown below, suppose we have a user-item interaction matrix $A$ with 10000 users and 100 items (10000 x 100), and its element `(j, k)` represents the rating of item `k` from user `j`. Then we could decompose $A$ into two smaller and dense matrices $U$ (10000 x 16) and $I$ (16 x 100). for user matrix $U$, each row vector is a transformed latent feature vector of a user, and for the item matrix $I$, each column is a transformed latent feature vector of an item.\n",
        "\n",
        "Here the dimension 16 is a hyperparameter defines the size of the hidden user and item features, which means now the shape of transposed user feature vector and item feature vector is now 16 x 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84xUtShg5hYr"
      },
      "source": [
        "The magic here is when we multiply the row `j` of $U$ and column `k` of matrix $I$, we can get an estimation to the original rating $\\hat{r}\\_{jk}$.\n",
        "\n",
        "For example, if we preform the dot product user ones  row vector in $U$ and item ones  column vector in $I$, we can get the rating estimation of user one to item one, which is the element (1, 1) in the original interaction matrix $I$. This r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEczf9rv5hYr"
      },
      "source": [
        "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module\\_4/images/nmf.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK33GgTq5hYs"
      },
      "source": [
        "Note $I$ is short for Items, and it is not an identity matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GnwRuOj5hYs"
      },
      "source": [
        "Then how do we figure out the values in $U$ and $I$ exactly? Like many other machine learning processes, we could start by initializing the values of $U$ and $I$, then define the following distance or cost function to be minimized:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVZNwQcj5hYt"
      },
      "source": [
        "$$\\sum\\_{r\\_{jk} \\in {train}} \\left(r\\_{jk} - \\hat{r}\\_{jk} \\right)^2,$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxiC1nO95hYt"
      },
      "source": [
        "where $\\hat{r}\\_{ij}$ is the dot product of $u_j^T$ and $i_k$:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmWHTMdw5hYu"
      },
      "source": [
        "$$\\hat{r}\\_{jk} = u_j^Ti_k$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApSRo7cE5hYu"
      },
      "source": [
        "The cost function can be optimized using stochastic gradient descent (SGD) or other optimization algorithms, just like in training the weights in a logistic regression model (there are several additional steps so the matrices have no negative elements) .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMT7-22y5hYu"
      },
      "source": [
        "## Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXto8U8-5hYv"
      },
      "source": [
        "*   Perform NMF-based collaborative filtering on the user-item matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U1FaTSl5hYv"
      },
      "source": [
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADziOpmp5hYw"
      },
      "source": [
        "### Load and exploring dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShrSYQyO5hYw"
      },
      "source": [
        "Let's first load our dataset, i.e., the user-item (learn-course) interaction matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIhFQtU25hYw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPloqTJd5hYy"
      },
      "outputs": [],
      "source": [
        "rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/ratings.csv\"\n",
        "rating_df = pd.read_csv(rating_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJfK7YpT5hYy",
        "outputId": "883dd2ae-62cb-4299-cfb8-a29cf0692d3f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1889878</td>\n",
              "      <td>CC0101EN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1342067</td>\n",
              "      <td>CL0101EN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1990814</td>\n",
              "      <td>ML0120ENv3</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>380098</td>\n",
              "      <td>BD0211EN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>779563</td>\n",
              "      <td>DS0101EN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      user        item  rating\n",
              "0  1889878    CC0101EN     3.0\n",
              "1  1342067    CL0101EN     3.0\n",
              "2  1990814  ML0120ENv3     3.0\n",
              "3   380098    BD0211EN     3.0\n",
              "4   779563    DS0101EN     3.0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rating_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK2TmOTj5hY0"
      },
      "source": [
        "The dataset contains three columns, `user id`, `item id`, and `the rating`. Note that this matrix is presented as the dense or vertical form, you may convert it using `pivot` to the original sparse matrix:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSqLzN_45hY0",
        "outputId": "4ec8569d-7823-4cd6-8a7d-52a0408c9a15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>AI0111EN</th>\n",
              "      <th>BC0101EN</th>\n",
              "      <th>BC0201EN</th>\n",
              "      <th>BC0202EN</th>\n",
              "      <th>BD0101EN</th>\n",
              "      <th>BD0111EN</th>\n",
              "      <th>BD0115EN</th>\n",
              "      <th>BD0121EN</th>\n",
              "      <th>BD0123EN</th>\n",
              "      <th>...</th>\n",
              "      <th>SW0201EN</th>\n",
              "      <th>TA0105</th>\n",
              "      <th>TA0105EN</th>\n",
              "      <th>TA0106EN</th>\n",
              "      <th>TMP0101EN</th>\n",
              "      <th>TMP0105EN</th>\n",
              "      <th>TMP0106</th>\n",
              "      <th>TMP107</th>\n",
              "      <th>WA0101EN</th>\n",
              "      <th>WA0103EN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 127 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   user  AI0111EN  BC0101EN  BC0201EN  BC0202EN  BD0101EN  BD0111EN  BD0115EN  \\\n",
              "0     2       0.0       3.0       0.0       0.0       3.0       2.0       0.0   \n",
              "1     4       0.0       0.0       0.0       0.0       2.0       2.0       2.0   \n",
              "2     5       2.0       2.0       2.0       0.0       2.0       0.0       0.0   \n",
              "3     7       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
              "4     8       0.0       0.0       0.0       0.0       0.0       2.0       0.0   \n",
              "\n",
              "   BD0121EN  BD0123EN  ...  SW0201EN  TA0105  TA0105EN  TA0106EN  TMP0101EN  \\\n",
              "0       2.0       2.0  ...       0.0     2.0       0.0       3.0        0.0   \n",
              "1       2.0       2.0  ...       0.0     2.0       0.0       0.0        0.0   \n",
              "2       0.0       2.0  ...       0.0     0.0       2.0       2.0        2.0   \n",
              "3       0.0       0.0  ...       0.0     0.0       0.0       0.0        0.0   \n",
              "4       0.0       0.0  ...       0.0     0.0       0.0       0.0        0.0   \n",
              "\n",
              "   TMP0105EN  TMP0106  TMP107  WA0101EN  WA0103EN  \n",
              "0        2.0      2.0     0.0       3.0       0.0  \n",
              "1        2.0      2.0     0.0       2.0       2.0  \n",
              "2        2.0      2.0     2.0       0.0       2.0  \n",
              "3        0.0      0.0     0.0       0.0       0.0  \n",
              "4        0.0      0.0     0.0       0.0       0.0  \n",
              "\n",
              "[5 rows x 127 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rating_sparse_df = rating_df.pivot(index='user', columns='item', values='rating').fillna(0).reset_index().rename_axis(index=None, columns=None)\n",
        "rating_sparse_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ3OrRD85hY1"
      },
      "source": [
        "## Implementation using **Surprise** library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXxvLjfM5hY1",
        "outputId": "0c72a889-481f-4f04-d569-3cf624020a05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise==1.1.1\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-surprise==1.1.1) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-surprise==1.1.1) (1.7.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from scikit-surprise==1.1.1) (1.16.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=781807 sha256=097aa598da55958d76703a3b4532f8fe8dceebe555a28f25af73ee2230d1cc4b\n",
            "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: joblib, scikit-surprise\n",
            "Successfully installed joblib-1.1.0 scikit-surprise-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-surprise==1.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPnlHtf45hY2"
      },
      "source": [
        "We import required classes and methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wASxqYJi5hY2"
      },
      "outputs": [],
      "source": [
        "from surprise import NMF\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsGeMqY55hY2"
      },
      "outputs": [],
      "source": [
        "rating_df.to_csv(\"course_ratings.csv\", index=False)\n",
        "# Read the course rating dataset with columns user item rating\n",
        "reader = Reader(\n",
        "        line_format='user item rating', sep=',', skip_lines=1, rating_scale=(2, 3))\n",
        "\n",
        "coruse_dataset = Dataset.load_from_file(\"course_ratings.csv\", reader=reader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9F26D9l5hY3"
      },
      "source": [
        "Now  we split the data into a train-set and test-set:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddueTG1u5hY3"
      },
      "outputs": [],
      "source": [
        "trainset, testset = train_test_split(coruse_dataset, test_size=.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz2Pm5Z95hY3"
      },
      "source": [
        "Then check how many users and items we can use to fit the KNN model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyqnXHNt5hY3",
        "outputId": "1ce9312a-a2c5-4880-9595-79f2be330fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total 31334 users and 123 items in the trainingset\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total {trainset.n_users} users and {trainset.n_items} items in the trainingset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aLFlqa25hY4"
      },
      "source": [
        "### Performing NMF-based collaborative filtering on the course-interaction matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnDkloKE5hY4"
      },
      "source": [
        "Fit a NMF model using the trainset and evaluate the results using the testset* The code will be very similar to the KNN-based collaborative filtering, you just need to use the `NMF()` model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWRjREX25hY4",
        "outputId": "372c4cd2-14ed-48c0-fe9e-a2edfe6e0526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing epoch 0\n",
            "Processing epoch 1\n",
            "Processing epoch 2\n",
            "Processing epoch 3\n",
            "Processing epoch 4\n",
            "Processing epoch 5\n",
            "Processing epoch 6\n",
            "Processing epoch 7\n",
            "Processing epoch 8\n",
            "Processing epoch 9\n",
            "Processing epoch 10\n",
            "Processing epoch 11\n",
            "Processing epoch 12\n",
            "Processing epoch 13\n",
            "Processing epoch 14\n",
            "Processing epoch 15\n",
            "Processing epoch 16\n",
            "Processing epoch 17\n",
            "Processing epoch 18\n",
            "Processing epoch 19\n",
            "Processing epoch 20\n",
            "Processing epoch 21\n",
            "Processing epoch 22\n",
            "Processing epoch 23\n",
            "Processing epoch 24\n",
            "Processing epoch 25\n",
            "Processing epoch 26\n",
            "Processing epoch 27\n",
            "Processing epoch 28\n",
            "Processing epoch 29\n",
            "Processing epoch 30\n",
            "Processing epoch 31\n",
            "Processing epoch 32\n",
            "Processing epoch 33\n",
            "Processing epoch 34\n",
            "Processing epoch 35\n",
            "Processing epoch 36\n",
            "Processing epoch 37\n",
            "Processing epoch 38\n",
            "Processing epoch 39\n",
            "Processing epoch 40\n",
            "Processing epoch 41\n",
            "Processing epoch 42\n",
            "Processing epoch 43\n",
            "Processing epoch 44\n",
            "Processing epoch 45\n",
            "Processing epoch 46\n",
            "Processing epoch 47\n",
            "Processing epoch 48\n",
            "Processing epoch 49\n",
            "RMSE: 0.1979\n",
            "RMSE 0.19785673369438034\n"
          ]
        }
      ],
      "source": [
        "NMF(verbose = True, random_state = 42)\n",
        "# - Train the NMF on the trainset, and predict ratings for the testset\n",
        "nmf.fit(trainset)\n",
        "# - Then compute RMSE\n",
        "predictions = nmf.test(testset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print('RMSE',rmse)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}